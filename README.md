# Artificial Neural Network Project


===============================================================================

## Table of Contents


===============================================================================

## 1. Introduction to Deep Learning

-	**Deep Learning** is a class of machine learning algorithms which depends on the structure and function of the brain called **Artificial Neural Network (ANN)**.
-	The term **Deep Learning** was introduced to the machine learning community by Rina Dechter in 1986 and to artificial neural networks by Igor Aizenberg and colleagues in 2000.
-	It uses multiple layers to progressively extract higher level features from raw input.
-	The term `deep` in deep learning refers to the number of layers through which the data is transformed.
-	In deep learning, each level learns to transform its input data into a slightly more abstract and composite representation.
-	Deep learning systems have a substantial `credit assignment path` (CAP) depth.
-	The CAP is the chain of transformations from input to output. CAPs describe potentially casual connections between input and output. 
-	Deep learning architectures are often constructed with a greedy layer-by-layer method. 
-	Deep learning helps to disentangle these abstractions and pick out which features improve performance.
-	Deep Learning systems are based on Neural Networks.
-	So, I will first discuss Neural Networks.

===============================================================================

## 2. Introduction to Neural Network 

-	Neural networks are a set of algorithms which are based on human brain.
-	These are artificial systems that were inspired by biological neural networks.
-	These are designed to recognize patterns in the data.
-	They interpret sensory data through a kind of machine perception, labelling or clustering raw input.
-	The patterns they recognize are numerical, contained in vectors, into which all real-world data (images, sound, text or time-series) must be translated.
-	Neural networks are based on computational models for threshold logic.
-	Threshold logic is a combination of algorithms and mathematics.
-	Components of a typical neural network involve neurons, connections, weights, biases, propagation function, and a learning rule. 
-	Neurons will receive an input pj(t) from predecessor neurons that have an activation aj(t), threshold , an activation function f, and an output function fout . 
-	Connections consist of connections, weights and biases which dictates how neuron i transfers output to neuron j. 
-	Propagation computes the input and outputs the output and sums the predecessor neurons function with the weight. The learning rule modifies the weights and thresholds of the variables in the network.

===============================================================================

===============================================================================

===============================================================================

===============================================================================

===============================================================================

===============================================================================

===============================================================================

===============================================================================
